'''
Lab 5
'''

######### Part 1 ###########
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

'''
    1-1) Download the iris-data-3 from Canvas, use pandas.read_csv to load it. This dataset has 5 input features: [sepal_length, sepal_width, petal_length, petal_width, color]
    1-2) Find and drop duplicate samples (use "ID" to find duplicates)
    1-3) Split your data into train(70% of data) and test(30% of data) via random selection
'''
# YOUR CODE GOES HERE
from random import randint
seed = input("Enter a Random Seed #: ")

try:
   RANDOM_SEED = int(seed)
except ValueError:
   RANDOM_SEED = randint(1,9999)
   print(f"\'{seed}\' is an invalid choice. Using {RANDOM_SEED} insead.")


with open('iris-data-3.csv') as csvfile:
    dff = pd.read_csv(csvfile, delimiter=',')
    dff.drop_duplicates('ID')
    X = pd.get_dummies(dff[['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'color']], columns=['color'])
    y = (dff["species"])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED)

'''
    2-1) Train a KNN classifier for the (k = 5, metric='manhattan'). Did you encounter an error? what is the error? how can we fix it?
    Fix the error and train your model. (Hint: pandas.get_dummies())
    2-2) Test your classifier with the test set and report the results.
    2-3) Print the confusion matrix for the results on the test set. 
'''
# YOUR CODE GOES HERE
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

KNeighbors = KNeighborsClassifier(n_neighbors=5, metric="manhattan")
KNeighbors.fit(X_train, y_train)
pred = KNeighbors.predict(X_test)
print("\n=================RESULTS Q2=================")
print(classification_report(y_test, pred))
print(confusion_matrix(y_test, pred))


'''
    3) Test your trained model with the given test set below and report the performance.
'''

X_test = np.asarray([[5 , 1, 0.2 , 5,'red'],[0.9 , 7, 6.2 , 2.1,'red'], [0.9 , 7, 6.2 , 2.1,'pink'] , [1.9 , 4, 5 , 0.1,'purple'], [5.9 , 3.3, 0.2 , 2.7,'blue']])
Y_test = np.asarray(['virginica', 'virginica','virginica', 'versicolor' ,'setosa'])

# YOUR CODE GOES HERE 
X_test = pd.DataFrame(X_test, columns= ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'color'])
Y_test = pd.DataFrame(Y_test, columns= ['species'])

X_test = pd.get_dummies(X_test, columns=['color'])
missing_cols = set(X.columns) - set(X_test.columns) # Incase some columns were not generated due to a smaller set

# This creates a new column with default value 0 for every missing column
# not generated by get_dummies. Ensures the same dimensions on all data.
for col in missing_cols:
    X_test[col] = 0

pred = KNeighbors.predict(X_test)

print("\n=================RESULTS Q3=================")
print(classification_report(Y_test, pred))
print(confusion_matrix(Y_test, pred))

'''
    4)  Use DictVectorizer from sklearn.feature_extraction to solve Q2
'''
# YOUR CODE GOES HERE  


'''
    5)  Use OneHotEncoder and LabelEncoder from sklearn.preprocessing to solve Q2
'''
# YOUR CODE GOES HERE  